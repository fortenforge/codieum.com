<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>Productionizing Context Aware Everything | Codeium · Free AI Code Completion &amp; Chat</title><meta name="robots" content="follow, index"/><meta name="description" content="Why it is hard to create a context reasoning engine for code LLMs that consistently works."/><meta property="og:url" content="https://codeium.com/blog/productionizing-context-aware-everything"/><meta property="og:type" content="article"/><meta property="og:site_name" content="Codeium · Free AI Code Completion &amp; Chat"/><meta property="og:description" content="Why it is hard to create a context reasoning engine for code LLMs that consistently works."/><meta property="og:title" content="Productionizing Context Aware Everything | Codeium · Free AI Code Completion &amp; Chat"/><meta property="og:image" content="https://exafunction.github.io/public/hero/hero_productionized_context_awareness.png"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="https://twitter.com/codeiumdev"/><meta name="twitter:title" content="Productionizing Context Aware Everything | Codeium · Free AI Code Completion &amp; Chat"/><meta name="twitter:description" content="Why it is hard to create a context reasoning engine for code LLMs that consistently works."/><meta name="twitter:image" content="https://exafunction.github.io/public/hero/hero_productionized_context_awareness.png"/><meta property="article:published_time" content="2023-08-03T07:00:00.000Z"/><link rel="canonical" href="productionizing-context-aware-everything"/><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://codeium.com/blog/productionizing-context-aware-everything"
  },
  "headline": "Productionizing Context Aware Everything | Codeium · Free AI Code Completion & Chat",
  "image": [
    {
      "@type": "ImageObject",
      "url": "https://exafunction.github.io/public/hero/hero_productionized_context_awareness.png"
    }
  ],
  "datePublished": "2023-08-03T07:00:00.000Z",
  "dateModified": "2023-08-03T07:00:00.000Z",
  "publisher": {
    "@type": "Organization",
    "name": "Exafunction Team",
    "logo": {
      "@type": "ImageObject",
      "url": "https://codeium.com/static/images/codeium-square-logo-small.png"
    }
  },
  "description": "Why it is hard to create a context reasoning engine for code LLMs that consistently works."
}</script><meta name="next-head-count" content="19"/><link rel="icon" href="../favicon.ico" sizes="any"/><link rel="icon" href="../favicon.svg" type="image/svg+xml"/><link rel="apple-touch-icon" href="../static/favicons/apple-touch-icon.png"/><link rel="manifest" href="../site.webmanifest"/><link rel="mask-icon" href="../favicon.svg" color="#09B6A2"/><meta name="msapplication-TileColor" content="#09B6A2"/><meta name="theme-color" content="#09B6A2"/><link rel="alternate" type="application/rss+xml" href="../feed.xml"/><link rel="preload" href="../_next/static/media/a867b47a386517bf-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="../_next/static/media/1549f4f270cb6be6-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="../_next/static/css/ab20e30d40808759.css" as="style" crossorigin=""/><link rel="stylesheet" href="../_next/static/css/ab20e30d40808759.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="../_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="../_next/static/chunks/webpack-e4a677b500b5999c.js" defer="" crossorigin=""></script><script src="../_next/static/chunks/framework-eecc82da3d7483c8.js" defer="" crossorigin=""></script><script src="../_next/static/chunks/main-365e64b898d454fe.js" defer="" crossorigin=""></script><script src="../_next/static/chunks/pages/_app-b18c057b02158ccd.js" defer="" crossorigin=""></script><script src="../_next/static/chunks/1275-10c1869f0bbf00dd.js" defer="" crossorigin=""></script><script src="../_next/static/chunks/7889-985592a7849b8efa.js" defer="" crossorigin=""></script><script src="../_next/static/chunks/pages/blog/[...slug]-069c086b04a1a686.js" defer="" crossorigin=""></script><script src="../_next/static/VBXOvo5BSUCiJzjePzBK3/_buildManifest.js" defer="" crossorigin=""></script><script src="../_next/static/VBXOvo5BSUCiJzjePzBK3/_ssgManifest.js" defer="" crossorigin=""></script><style id="__jsx-303972100">:root{--default-font:'__Assistant_6ce12c', '__Assistant_Fallback_6ce12c';--header-font:'__Lexend_b77898', '__Lexend_Fallback_b77898';--mono-font:Courier, monospace}</style></head><body class="bg-site-background text-white antialiased"><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&false)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}else{c.add('dark')}if(e==='light'||e==='dark'||!e)d.style.colorScheme=e||'dark'}catch(e){}}()</script><header class="mb-[35px] flex w-full items-center justify-between px-4 py-4 md:mb-[70px]"><div class="flex grow-0 flex-row items-center justify-center"><a aria-label="Codeium" class="transition-all duration-150" href="../index.html"><div class="flex items-center justify-between"><div class="mr-2 px-3"><svg viewBox="0 0 1989 450" fill="none" xmlns="http://www.w3.org/2000/svg" height="40"><path fill-rule="evenodd" clip-rule="evenodd" d="M392.971 32.0294L200 225L392.971 417.971C397.314 413.627 400 407.627 400 401V49C400 42.3726 397.314 36.3726 392.971 32.0294Z" fill="#60D5C4"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M392.971 32.0294L200 225L7.02942 32.0294C11.3726 27.6863 17.3726 25 24 25H376C382.627 25 388.627 27.6863 392.971 32.0294Z" fill="#71E9D8"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M7.02944 32.0294L200 225L7.02944 417.971C2.68629 413.627 0 407.627 0 401V49C0 42.3726 2.68629 36.3726 7.02944 32.0294Z" fill="#60D5C4"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M392.971 417.971L200 225L7.02942 417.971C11.3726 422.314 17.3726 425 24 425H376C382.627 425 388.627 422.314 392.971 417.971Z" fill="#71E9D8"></path><rect x="50" y="75" width="300" height="300" rx="2" fill="#09B6A2"></rect><path d="M120.8 315.12C101.24 315.12 91.46 305.34 91.46 285.78V243.84C91.46 236.52 87.86 232.86 80.66 232.86C78.02 232.86 75.8 232.02 74 230.34C72.32 228.66 71.48 226.5 71.48 223.86C71.48 221.1 72.32 218.88 74 217.2C75.8 215.52 78.02 214.68 80.66 214.68C87.86 214.68 91.46 211.02 91.46 203.7V161.76C91.46 142.2 101.24 132.42 120.8 132.42C123.44 132.42 125.6 133.32 127.28 135.12C128.96 136.92 129.8 139.14 129.8 141.78C129.8 144.42 128.96 146.58 127.28 148.26C125.6 149.94 123.44 150.78 120.8 150.78C113.48 150.78 109.82 154.44 109.82 161.76V203.7C109.82 207.9 109.34 211.68 108.38 215.04C107.42 218.4 105.98 221.34 104.06 223.86C107.9 228.78 109.82 235.44 109.82 243.84V285.78C109.82 293.1 113.48 296.76 120.8 296.76C123.44 296.76 125.6 297.6 127.28 299.28C128.96 300.96 129.8 303.18 129.8 305.94C129.8 308.58 128.96 310.74 127.28 312.42C125.6 314.22 123.44 315.12 120.8 315.12ZM156.733 275.88C153.373 275.88 150.433 274.68 147.913 272.28C145.513 269.76 144.313 266.82 144.313 263.46C144.313 259.98 145.513 257.04 147.913 254.64C150.433 252.12 153.373 250.86 156.733 250.86C160.213 250.86 163.153 252.12 165.553 254.64C167.953 257.04 169.153 259.98 169.153 263.46C169.153 266.82 167.953 269.76 165.553 272.28C163.153 274.68 160.213 275.88 156.733 275.88ZM199.623 275.88C196.263 275.88 193.323 274.68 190.803 272.28C188.403 269.76 187.203 266.82 187.203 263.46C187.203 259.98 188.403 257.04 190.803 254.64C193.323 252.12 196.263 250.86 199.623 250.86C203.103 250.86 206.043 252.12 208.443 254.64C210.843 257.04 212.043 259.98 212.043 263.46C212.043 266.82 210.843 269.76 208.443 272.28C206.043 274.68 203.103 275.88 199.623 275.88ZM242.514 275.88C239.154 275.88 236.214 274.68 233.694 272.28C231.294 269.76 230.094 266.82 230.094 263.46C230.094 259.98 231.294 257.04 233.694 254.64C236.214 252.12 239.154 250.86 242.514 250.86C245.994 250.86 248.934 252.12 251.334 254.64C253.734 257.04 254.934 259.98 254.934 263.46C254.934 266.82 253.734 269.76 251.334 272.28C248.934 274.68 245.994 275.88 242.514 275.88ZM278.564 315.12C275.924 315.12 273.764 314.22 272.084 312.42C270.404 310.74 269.564 308.58 269.564 305.94C269.564 303.18 270.404 300.96 272.084 299.28C273.764 297.6 275.924 296.76 278.564 296.76C285.884 296.76 289.544 293.1 289.544 285.78V243.84C289.544 235.44 291.464 228.78 295.304 223.86C293.384 221.34 291.944 218.4 290.984 215.04C290.024 211.68 289.544 207.9 289.544 203.7V161.76C289.544 154.44 285.884 150.78 278.564 150.78C275.924 150.78 273.764 149.94 272.084 148.26C270.404 146.58 269.564 144.42 269.564 141.78C269.564 139.14 270.404 136.92 272.084 135.12C273.764 133.32 275.924 132.42 278.564 132.42C298.124 132.42 307.904 142.2 307.904 161.76V203.7C307.904 211.02 311.504 214.68 318.704 214.68C321.344 214.68 323.504 215.52 325.184 217.2C326.984 218.88 327.884 221.1 327.884 223.86C327.884 226.5 326.984 228.66 325.184 230.34C323.504 232.02 321.344 232.86 318.704 232.86C311.504 232.86 307.904 236.52 307.904 243.84V285.78C307.904 305.34 298.124 315.12 278.564 315.12Z" fill="white"></path><path d="M592.2 363.6C574.68 363.6 558.96 359.28 545.04 350.64C531.36 342 520.44 330.24 512.28 315.36C504.36 300.48 500.4 283.8 500.4 265.32C500.4 246.84 504.36 230.16 512.28 215.28C520.44 200.4 531.36 188.64 545.04 180C558.96 171.36 574.68 167.04 592.2 167.04C609 167.04 624.24 170.52 637.92 177.48C651.84 184.2 662.4 193.44 669.6 205.2L649.08 230.4C645.24 224.88 640.32 219.84 634.32 215.28C628.32 210.72 621.96 207.12 615.24 204.48C608.52 201.84 602.04 200.52 595.8 200.52C584.28 200.52 573.96 203.4 564.84 209.16C555.96 214.68 548.88 222.36 543.6 232.2C538.32 242.04 535.68 253.08 535.68 265.32C535.68 277.56 538.44 288.6 543.96 298.44C549.48 308.04 556.8 315.72 565.92 321.48C575.04 327.24 585.12 330.12 596.16 330.12C602.64 330.12 608.88 329.04 614.88 326.88C621.12 324.72 627.12 321.48 632.88 317.16C638.64 312.84 644.04 307.56 649.08 301.32L669.6 326.52C661.92 337.32 650.88 346.2 636.48 353.16C622.32 360.12 607.56 363.6 592.2 363.6ZM789.536 363.6C771.056 363.6 754.496 359.4 739.856 351C725.456 342.36 714.056 330.72 705.656 316.08C697.256 301.2 693.056 284.28 693.056 265.32C693.056 246.36 697.256 229.56 705.656 214.92C714.056 200.04 725.456 188.4 739.856 180C754.496 171.36 771.056 167.04 789.536 167.04C807.776 167.04 824.096 171.36 838.496 180C853.136 188.4 864.656 200.04 873.056 214.92C881.456 229.56 885.656 246.36 885.656 265.32C885.656 284.28 881.456 301.2 873.056 316.08C864.656 330.72 853.136 342.36 838.496 351C824.096 359.4 807.776 363.6 789.536 363.6ZM789.536 329.76C800.816 329.76 810.896 327 819.776 321.48C828.656 315.72 835.616 308.04 840.656 298.44C845.696 288.6 848.096 277.56 847.856 265.32C848.096 252.84 845.696 241.8 840.656 232.2C835.616 222.36 828.656 214.68 819.776 209.16C810.896 203.64 800.816 200.88 789.536 200.88C778.256 200.88 768.056 203.76 758.936 209.52C750.056 215.04 743.096 222.72 738.056 232.56C733.016 242.16 730.616 253.08 730.856 265.32C730.616 277.56 733.016 288.6 738.056 298.44C743.096 308.04 750.056 315.72 758.936 321.48C768.056 327 778.256 329.76 789.536 329.76ZM1004.9 363.6C987.621 363.6 972.141 359.4 958.461 351C945.021 342.36 934.341 330.72 926.421 316.08C918.501 301.2 914.541 284.28 914.541 265.32C914.541 246.36 918.381 229.56 926.061 214.92C933.981 200.04 944.661 188.4 958.101 180C971.541 171.36 986.781 167.04 1003.82 167.04C1013.18 167.04 1022.18 168.6 1030.82 171.72C1039.7 174.6 1047.62 178.68 1054.58 183.96C1061.54 189 1066.94 194.64 1070.78 200.88C1074.86 206.88 1076.9 213 1076.9 219.24L1066.1 219.96V93.6H1103.18V360H1066.1V315H1073.3C1073.3 320.76 1071.38 326.52 1067.54 332.28C1063.7 337.8 1058.54 342.96 1052.06 347.76C1045.82 352.56 1038.5 356.4 1030.1 359.28C1021.94 362.16 1013.54 363.6 1004.9 363.6ZM1009.94 331.56C1021.22 331.56 1031.18 328.68 1039.82 322.92C1048.46 317.16 1055.18 309.36 1059.98 299.52C1065.02 289.44 1067.54 278.04 1067.54 265.32C1067.54 252.6 1065.02 241.32 1059.98 231.48C1055.18 221.4 1048.46 213.48 1039.82 207.72C1031.18 201.96 1021.22 199.08 1009.94 199.08C998.661 199.08 988.701 201.96 980.061 207.72C971.421 213.48 964.581 221.4 959.541 231.48C954.741 241.32 952.341 252.6 952.341 265.32C952.341 278.04 954.741 289.44 959.541 299.52C964.581 309.36 971.421 317.16 980.061 322.92C988.701 328.68 998.661 331.56 1009.94 331.56ZM1242.42 363.6C1222.98 363.6 1205.7 359.52 1190.58 351.36C1175.7 342.96 1163.94 331.56 1155.3 317.16C1146.9 302.76 1142.7 286.2 1142.7 267.48C1142.7 252.6 1145.1 239.04 1149.9 226.8C1154.7 214.56 1161.3 204 1169.7 195.12C1178.34 186 1188.54 179.04 1200.3 174.24C1212.3 169.2 1225.26 166.68 1239.18 166.68C1251.42 166.68 1262.82 169.08 1273.38 173.88C1283.94 178.44 1293.06 184.8 1300.74 192.96C1308.66 201.12 1314.66 210.84 1318.74 222.12C1323.06 233.16 1325.1 245.28 1324.86 258.48L1324.5 274.32H1170.06L1161.78 244.8H1292.46L1287.06 250.92V242.28C1286.34 234.36 1283.7 227.28 1279.14 221.04C1274.58 214.8 1268.82 209.88 1261.86 206.28C1254.9 202.68 1247.34 200.88 1239.18 200.88C1226.22 200.88 1215.3 203.4 1206.42 208.44C1197.54 213.24 1190.82 220.44 1186.26 230.04C1181.7 239.4 1179.42 251.04 1179.42 264.96C1179.42 278.16 1182.18 289.68 1187.7 299.52C1193.22 309.12 1201.02 316.56 1211.1 321.84C1221.18 327.12 1232.82 329.76 1246.02 329.76C1255.38 329.76 1264.02 328.2 1271.94 325.08C1280.1 321.96 1288.86 316.32 1298.22 308.16L1316.94 334.44C1311.18 340.2 1304.1 345.24 1295.7 349.56C1287.54 353.88 1278.78 357.36 1269.42 360C1260.3 362.4 1251.3 363.6 1242.42 363.6ZM1371.28 360V171H1408.36V360H1371.28ZM1389.28 129.24C1381.36 129.24 1375.24 127.2 1370.92 123.12C1366.6 119.04 1364.44 113.28 1364.44 105.84C1364.44 98.88 1366.6 93.24 1370.92 88.92C1375.48 84.6 1381.6 82.44 1389.28 82.44C1397.2 82.44 1403.32 84.48 1407.64 88.56C1411.96 92.64 1414.12 98.4 1414.12 105.84C1414.12 112.8 1411.84 118.44 1407.28 122.76C1402.96 127.08 1396.96 129.24 1389.28 129.24ZM1531.6 363.6C1518.16 363.6 1506.4 360.48 1496.32 354.24C1486.48 348 1478.8 339.24 1473.28 327.96C1468 316.68 1465.36 303.24 1465.36 287.64V171H1502.44V277.56C1502.44 288.6 1504.12 298.2 1507.48 306.36C1511.08 314.28 1516.12 320.4 1522.6 324.72C1529.32 329.04 1537.36 331.2 1546.72 331.2C1553.68 331.2 1560.04 330.12 1565.8 327.96C1571.56 325.56 1576.48 322.32 1580.56 318.24C1584.88 314.16 1588.24 309.24 1590.64 303.48C1593.04 297.72 1594.24 291.48 1594.24 284.76V171H1631.32V360H1594.24V320.4L1600.72 316.08C1597.84 324.96 1592.92 333 1585.96 340.2C1579.24 347.4 1571.2 353.16 1561.84 357.48C1552.48 361.56 1542.4 363.6 1531.6 363.6ZM1682.61 360V171H1720.05V211.32L1713.21 215.64C1715.13 209.4 1718.13 203.4 1722.21 197.64C1726.53 191.88 1731.69 186.84 1737.69 182.52C1743.93 177.96 1750.53 174.36 1757.49 171.72C1764.69 169.08 1772.01 167.76 1779.45 167.76C1790.25 167.76 1799.73 169.56 1807.89 173.16C1816.05 176.76 1822.77 182.16 1828.05 189.36C1833.33 196.56 1837.17 205.56 1839.57 216.36L1833.81 214.92L1836.33 208.8C1838.97 203.28 1842.57 198.12 1847.13 193.32C1851.93 188.28 1857.33 183.84 1863.33 180C1869.33 176.16 1875.69 173.16 1882.41 171C1889.13 168.84 1895.73 167.76 1902.21 167.76C1916.37 167.76 1928.01 170.64 1937.13 176.4C1946.49 182.16 1953.45 190.92 1958.01 202.68C1962.81 214.44 1965.21 229.08 1965.21 246.6V360H1927.77V248.76C1927.77 237.96 1926.33 229.2 1923.45 222.48C1920.81 215.52 1916.73 210.36 1911.21 207C1905.69 203.64 1898.61 201.96 1889.97 201.96C1883.25 201.96 1876.89 203.16 1870.89 205.56C1865.13 207.72 1860.09 210.84 1855.77 214.92C1851.45 219 1848.09 223.8 1845.69 229.32C1843.29 234.6 1842.09 240.48 1842.09 246.96V360H1804.65V248.04C1804.65 238.2 1803.21 229.92 1800.33 223.2C1797.45 216.24 1793.25 210.96 1787.73 207.36C1782.21 203.76 1775.49 201.96 1767.57 201.96C1760.85 201.96 1754.61 203.16 1748.85 205.56C1743.09 207.72 1738.05 210.84 1733.73 214.92C1729.41 218.76 1726.05 223.44 1723.65 228.96C1721.25 234.24 1720.05 240 1720.05 246.24V360H1682.61Z" fill="#09B6A2"></path></svg></div></div></a></div><div class="hidden grow flex-row flex-wrap justify-end md:flex"><div class="flex items-center justify-center"><a class="px-2 text-white hover:text-surface-200 md:px-3 lg:px-4" href="../pricing">Pricing</a></div><div class="flex items-center justify-center"><a class="hidden md:flex px-2 text-white hover:text-surface-200 md:px-3 lg:px-4" href="../chat">Chat</a></div><div class="flex items-center justify-center"><a class="hidden md:flex px-2 text-white hover:text-surface-200 md:px-3 lg:px-4" href="../enterprise">Enterprise</a></div><div class="flex items-center justify-center"><a class="hidden md:flex px-2 text-white hover:text-surface-200 md:px-3 lg:px-4" href="../playground">Playground</a></div><div class="flex items-center justify-center"><a class="hidden lg:flex px-2 text-white hover:text-surface-200 md:px-3 lg:px-4" href="../blog">Blog</a></div><div class="relative inline-block text-left px-2 md:px-3 lg:px-4" data-headlessui-state=""><div><button class="inline-flex items-center gap-x-1 leading-6 text-white hover:text-surface-300 transition-colors" id="headlessui-menu-button-:R3id56:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open options</span>Company<!-- --> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" class="h-4 w-4"><path fill-rule="evenodd" d="M12.53 16.28a.75.75 0 01-1.06 0l-7.5-7.5a.75.75 0 011.06-1.06L12 14.69l6.97-6.97a.75.75 0 111.06 1.06l-7.5 7.5z" clip-rule="evenodd"></path></svg></button></div></div></div><div class="flex grow flex-row items-center justify-end md:grow-0"><a target="_blank" rel="noopener noreferrer" href="https://discord.gg/3XFf78nAx5" class="w-12 text-center text-gray-50 transition-all duration-150"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="28" height="28" class="m-auto fill-white"><title>Discord</title><path d="M20.317 4.3698a19.7913 19.7913 0 00-4.8851-1.5152.0741.0741 0 00-.0785.0371c-.211.3753-.4447.8648-.6083 1.2495-1.8447-.2762-3.68-.2762-5.4868 0-.1636-.3933-.4058-.8742-.6177-1.2495a.077.077 0 00-.0785-.037 19.7363 19.7363 0 00-4.8852 1.515.0699.0699 0 00-.0321.0277C.5334 9.0458-.319 13.5799.0992 18.0578a.0824.0824 0 00.0312.0561c2.0528 1.5076 4.0413 2.4228 5.9929 3.0294a.0777.0777 0 00.0842-.0276c.4616-.6304.8731-1.2952 1.226-1.9942a.076.076 0 00-.0416-.1057c-.6528-.2476-1.2743-.5495-1.8722-.8923a.077.077 0 01-.0076-.1277c.1258-.0943.2517-.1923.3718-.2914a.0743.0743 0 01.0776-.0105c3.9278 1.7933 8.18 1.7933 12.0614 0a.0739.0739 0 01.0785.0095c.1202.099.246.1981.3728.2924a.077.077 0 01-.0066.1276 12.2986 12.2986 0 01-1.873.8914.0766.0766 0 00-.0407.1067c.3604.698.7719 1.3628 1.225 1.9932a.076.076 0 00.0842.0286c1.961-.6067 3.9495-1.5219 6.0023-3.0294a.077.077 0 00.0313-.0552c.5004-5.177-.8382-9.6739-3.5485-13.6604a.061.061 0 00-.0312-.0286zM8.02 15.3312c-1.1825 0-2.1569-1.0857-2.1569-2.419 0-1.3332.9555-2.4189 2.157-2.4189 1.2108 0 2.1757 1.0952 2.1568 2.419 0 1.3332-.9555 2.4189-2.1569 2.4189zm7.9748 0c-1.1825 0-2.1569-1.0857-2.1569-2.419 0-1.3332.9554-2.4189 2.1569-2.4189 1.2108 0 2.1757 1.0952 2.1568 2.419 0 1.3332-.946 2.4189-2.1568 2.4189Z"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="w-12 cursor-pointer text-center text-gray-50 font-light hover:font-black transition-all duration-150" alt="Login"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="28" height="28" class="fill-white"><path d="M12 2a5 5 0 1 0 5 5 5 5 0 0 0-5-5zm0 8a3 3 0 1 1 3-3 3 3 0 0 1-3 3zm9 11v-1a7 7 0 0 0-7-7h-4a7 7 0 0 0-7 7v1h2v-1a5 5 0 0 1 5-5h4a5 5 0 0 1 5 5v1z"></path></svg></a><a class="transition-all duration-150" href="../download"><button style="border:none;background-size:300% 100%;transition:all 0.3s ease;background-image:linear-gradient(-60deg, #09b6a2, #6bf8e7, #09b6a2);background-position:100% 0" class="group flex h-14 items-center justify-center rounded-lg text-lg font-semibold text-white transition-all duration-100 glow-sm hover:glow-md ml-1 hidden h-9 w-28 text-sm sm:block">Get Codeium</button></a></div><div class="ml-3 md:ml-0 md:hidden"><button type="button" class="h-8 w-8 rounded py-1" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-50"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="fixed right-0 top-20 z-20 h-full w-full transform overflow-y-auto bg-gray-50 opacity-95 duration-100 ease-in-out translate-x-full"><nav class="mb-20 mt-4 flex w-full flex-col"><a class="w-full px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500 transition-all duration-150" href="../index.html">Home</a><a class="w-full px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500 transition-all duration-150" href="../pricing">Pricing</a><a class="w-full px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500 transition-all duration-150" href="../chat">Chat</a><a class="w-full px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500 transition-all duration-150" href="../enterprise">Enterprise</a><a class="w-full px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500 transition-all duration-150" href="../blog">Blog</a><a class="w-full px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500 transition-all duration-150" href="../playground">Playground</a><div class="flex w-full cursor-pointer flex-row items-center justify-between px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500"><div>Company</div><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="h-8 w-8 text-gray-900"><path d="M16.293 9.293 12 13.586 7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z"></path></svg></div><a class="w-full px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500 transition-all duration-150" href="../download">Extensions</a><a class="w-full px-12 py-4 text-2xl font-bold tracking-widest text-gray-900 hover:text-primary-500 transition-all duration-150" href="../profile">Login</a></nav></div></div></header><div class="mx-auto flex w-full max-w-5xl xl:max-w-6xl flex-col px-4 " aria-label="section-container-standard"><div class="flex flex-col justify-between" style="flex-grow:1"><main class="mb-auto"><div class="mx-auto flex max-w-7xl flex-col px-6 md:px-12"><div class="fixed bottom-8 right-8 hidden flex-col gap-3 md:hidden"><button aria-label="Scroll To Comment" type="button" class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300"><svg class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M18 10c0 3.866-3.582 7-8 7a8.841 8.841 0 01-4.083-.98L2 17l1.338-3.123C2.493 12.767 2 11.434 2 10c0-3.866 3.582-7 8-7s8 3.134 8 7zM7 9H5v2h2V9zm8 0h-2v2h2V9zM9 9h2v2H9V9z" clip-rule="evenodd"></path></svg></button><button aria-label="Scroll To Top" type="button" class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300"><svg class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z" clip-rule="evenodd"></path></svg></button></div><article><header><div class="space-y-1 border-b border-gray-200 pb-10 text-center"><dl><div><dt class="sr-only">Published on</dt><dd class="mb-8 mt-8 text-base font-medium leading-6 text-white"><time dateTime="2023-08-03T07:00:00.000Z">August 3, 2023</time></dd></div></dl><div><h1 class="md:leading-14 text-center text-3xl font-extrabold leading-9 tracking-tight text-white sm:text-4xl sm:leading-10 md:text-5xl">Productionizing Context Aware Everything</h1></div><dl><div><dt class="sr-only">Written by</dt><dd class="mt-4 text-base font-medium leading-6 text-white">Nick Moy, Anshul Ramachandran</dd></div></dl></div></header><div class="mt-10 gap-8 sm:grid sm:grid-cols-9"><div class="hidden sm:col-span-2 sm:block"><div class="sticky top-8"><div class="rounded-md bg-neutral-700 p-4"><h4 class="mb-2 text-lg font-bold">Contents</h4><div class="mb-2 overflow-x-hidden" style="padding-left:8px"><a href="productionizing-context-aware-everything#background-on-realtime-context" class="text-brand-dark-300">Background on Realtime Context</a></div><div class="mb-2 overflow-x-hidden" style="padding-left:8px"><a href="productionizing-context-aware-everything#challenges-with-context-retrieval-for-coding-tasks" class="text-brand-dark">Challenges with Context Retrieval for Coding Tasks</a></div><div class="mb-2 overflow-x-hidden" style="padding-left:16px"><a href="productionizing-context-aware-everything#cross-domain" class="text-brand-dark">Cross-Domain</a></div><div class="mb-2 overflow-x-hidden" style="padding-left:16px"><a href="productionizing-context-aware-everything#context-fragmentation" class="text-brand-dark">Context Fragmentation</a></div><div class="mb-2 overflow-x-hidden" style="padding-left:16px"><a href="productionizing-context-aware-everything#entity-rarity" class="text-brand-dark">Entity Rarity</a></div><div class="mb-2 overflow-x-hidden" style="padding-left:16px"><a href="productionizing-context-aware-everything#latency-constraints" class="text-brand-dark">Latency Constraints</a></div><div class="mb-2 overflow-x-hidden" style="padding-left:8px"><a href="productionizing-context-aware-everything#productionizing-context-aware-everything" class="text-brand-dark">Productionizing Context Aware Everything</a></div><div class="mb-2 overflow-x-hidden" style="padding-left:8px"><a href="productionizing-context-aware-everything#bringing-context-aware-everything-to-enterprises" class="text-brand-dark">Bringing Context Aware Everything to Enterprises</a></div><div class="mb-2 overflow-x-hidden" style="padding-left:8px"><a href="productionizing-context-aware-everything#final-thoughts-on-context-awareness" class="text-brand-dark">Final Thoughts on Context Awareness</a></div></div></div></div><div class="sm:col-span-7"><div class="divide-y divide-white pb-8 xl:divide-y-0 " style="grid-template-rows:auto 1fr"><div class="divide-y divide-white xl:col-span-3 xl:row-span-2 xl:pb-0"><div class="prose max-w-none pb-8 text-white"><div class="m-auto w-full max-w-2xl"><img src="https://exafunction.github.io/public/hero/hero_productionized_context_awareness.png" class="h-full w-full " alt="A robot meditating and observing the universe."/></div><p class="text-base sm:text-lg"><strong>TL;DR We at Codeium are always looking for ways to improve on our enterprise product to give our customers the best suggestions to maximize their productivity. Here, we discuss how we productionized our industry-leading code context collection and prompt building, in a way that actually makes sense for companies. Codeium for Enterprises is the only AI assistant tool that properly productionizes using realtime context.</strong></p><h1 id="background-on-realtime-context"><a href="productionizing-context-aware-everything#background-on-realtime-context" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Background on Realtime Context</h1><p class="text-base sm:text-lg">First, we discussed <a class="transition-all duration-150" href="what-to-know-about-the-context-going-into-your-llm">why context collection is an important, yet tricky, part of an AI code assistance stack</a>, and then <a class="transition-all duration-150" href="context-aware-everything-more-advanced-realtime-context-than-github-copilot">we showed that if done properly, advanced context awareness leads to dramatically better performance</a>, pushing the quality of Codeium’s code suggestions far past other industry leaders like GitHub Copilot.</p><p class="text-base sm:text-lg">So now that we have proven how well context retrieval can work, <strong>let us get into the details of what such a retrieval stack looks like</strong>. Given all of the popular discourse on LLMs, most people would converge on a stack that looks a little like this:</p><ul><li class="text-base sm:text-lg">Indexing (ahead-of-time): First, chunk up your knowledge base into context-sized chunks overlapping chunks somewhat to account for badly placed splits. Then embed these chunks using some 3rd party embedding API (ex. OpenAI ADA embedding), and then store the embeddings in a vector database (ex. PineconeDB).</li><li class="text-base sm:text-lg">Retrieval (real-time): First, use your remote embedding API to embed the user chat message/query. Then, use cosine similarity to match the resulting embedding to the K nearest items in your vector database and put those items into the prompt in addition to the original input. Profit</li></ul><p class="text-base sm:text-lg"><strong>Naturally, indexing + retrieval is the first thing we tried as well, and it worked! Well, it worked often enough if all we wanted to do was record some cool demo videos of cherry-picked examples. But at Codeium, we have actual users (hundreds of thousands of them), and our features have to work without cherrypicking. So we dug in to understand how to build a system that would address the unique challenges of context for coding.</strong></p><h1 id="challenges-with-context-retrieval-for-coding-tasks"><a href="productionizing-context-aware-everything#challenges-with-context-retrieval-for-coding-tasks" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Challenges with Context Retrieval for Coding Tasks</h1><p class="text-base sm:text-lg">So let’s walk through some of these challenges, in no particular order.</p><p class="text-base sm:text-lg">Note that we are focused here on the retrieval system itself and how do we get the accuracy of this system high enough to be useful. None of these address training the autocomplete or chat model to actually use retrieved context as opposed to just shoving in the retrieved chunks and hoping the LLM can figure out what to do with them. But that’s a topic for another post.</p><h2 id="cross-domain"><a href="productionizing-context-aware-everything#cross-domain" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Cross-Domain</h2><p class="text-base sm:text-lg">Take a chat functionality for code assistance. Users often ask questions in natural language, but a lot of the relevant context is in code! It also goes the other way, where if you want to explain some code, the relevant context will be in documentation, which is natural language. The user-specified input is in a different domain from the context that you want to retrieve. <strong>Any production codebase in itself has a mix of natural language and programming languages, and off-the shelf embedding models don’t capture this cross-modal relationship well.</strong></p><h2 id="context-fragmentation"><a href="productionizing-context-aware-everything#context-fragmentation" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Context Fragmentation</h2><p class="text-base sm:text-lg">In many applications and most academic benchmarks (eg. WikiQA) the “correct answer” is in exactly one place in one document. In code this is almost never the case. <strong>In a common, decently-structured codebase, often 80% of the nominal functionality of a file is imported from libraries that exist all over the codebase. Those libraries will be hard to find based on naive embedding search</strong> – a general-purpose library will contain very little information on all the ways in which it ends up being used. Somehow your retrieval system has to trace the relationships between files that have little overlapping content, to ensure it pulls all the right items.</p><p class="text-base sm:text-lg">To further complicate the context fragmentation problem, <strong>a question about the same overall topic, asked at two different levels of detail, might require completely different actual fragments of context to answer</strong>. “How does our debugger work” vs. “What library do we use to parse error stack traces in our debugger” touch on the same topic, but at very different scopes, requiring different levels of summarization. One might involve pulling the summary of a few classes that interact with each other. The latter might require pulling a specific method from within one of those classes.</p><h2 id="entity-rarity"><a href="productionizing-context-aware-everything#entity-rarity" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Entity Rarity</h2><p class="text-base sm:text-lg">Prior to embedding search, so-called “sparse” retrieval (a fancy word for word-matching algorithms) was state of the art for document retrieval. The reason why embeddings are hugely helpful to context retrieval systems is that they are capable of fuzzy matching, where there’s a fundamental underlying relationship between the search query and the target entity, even when none of the words used are the same. This way, a user can ask very vague questions without any reference to a specific filename, and still get reasonable responses.</p><p class="text-base sm:text-lg">However, <a target="_blank" rel="noopener noreferrer" href="https://www.semanticscholar.org/reader/f7a6b57adebb5f6a10d16e120f0b0ef55aab7b2b" class="transition-all duration-150">research shows</a> that <strong>for rare entities, and especially zero-shot entities that the embedding model did not see at training, embedding-based retrieval systems still significantly underperform traditional “Sparse” (word matching) based retrievers</strong>. The research goes into more detail on why, but as some intuition, imagine studying for a test: if you need to know a formula well enough to actually use it to solve a problem, you need to have seen the pattern more times than if you just want to know the the “gist” of an idea. In a similar way, rarer items will be less well represented by an embedding model.</p><p class="text-base sm:text-lg"><strong>Unfortunately, rare entities are very important for any coding related task.</strong> Code is full of them - unlike natural language, code is special in that you can use arbitrary strings of characters for an entity, or more interestingly, redefine what an entity means within the context of your repository, even if that differs from what it means in a different repository. In a very fundamental sense, this is the entire point of code. And once you define that new entity, its name may appear only a handful of times in a codebase: once when the function is defined and just a few more times when that function is called.</p><p class="text-base sm:text-lg">But to simultaneously raise the stakes, it is also very important for our system to get the specific entity correctly to provide a useful suggestion. For example, we need to know exactly what the parameter list of a function is, not that of a similar function that does something similar.</p><h2 id="latency-constraints"><a href="productionizing-context-aware-everything#latency-constraints" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Latency Constraints</h2><p class="text-base sm:text-lg">For autocomplete, completion requests are produced with every keystroke. The typical autocompletion takes 100ms, and you cannot really get a whole lot slower if you want to keep developers in the flow. So, <strong>if a context retrieval system is going to be used, it can’t add on much more than 20ms on average or it will start to negatively affect the user experience</strong>.</p><p class="text-base sm:text-lg">Performing an embedding of the input takes about 100ms, and if you were to use a remote service or embedding API, you would incur another 100ms or so in network latency to the remote service. The actual similarity calculation is pretty fast since it boils down to just a matrix multiplication, but the embedding makes it impossible to do for every autocomplete request.</p><p class="text-base sm:text-lg">Sparse heuristics on the other hand have less up-front compute cost, but this cost scales with the number of items that we need to retrieve and rank, and quickly becomes unmanageable over millions of records.</p><h1 id="productionizing-context-aware-everything"><a href="productionizing-context-aware-everything#productionizing-context-aware-everything" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Productionizing Context Aware Everything</h1><p class="text-base sm:text-lg">Of course we won’t just list out challenges without providing a little bit of insight in how we solved these issues to get the results demonstrated in the <a class="transition-all duration-150" href="context-aware-everything-more-advanced-realtime-context-than-github-copilot">previous post</a>.</p><ul><li class="text-base sm:text-lg"><strong>Cross Domain</strong>: We trained our own embedding model specifically to map between natural language and code using docstrings as the natural language. This is actually what underlies our <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=fk5pod16678" class="transition-all duration-150">search capability</a>, which, as an aside, we are slowly going to be folding directly into chat as chat becomes more “context aware” to be able to answer these direct search questions. With this, it is important for us to semantically parse concepts like docstrings from the code itself, and this led to our <a target="_blank" rel="noopener noreferrer" href="https://github.com/Exafunction/codeium-parse" class="transition-all duration-150">codeium-parse library</a>. When we do embedding retrieval, we might get a hit on the docstring specifically to match the natural language, and that lets us retrieve the code snippet, which is what the user actually needs. When indexing a codebase, we often index multiple parts of the same code item, allowing us more opportunities to get a hit since we have semantically linked these parts via parsing.</li><li class="text-base sm:text-lg"><strong>Context Fragmentation</strong>: The first step is multi-key retrieval. Whether the input is a chat question or autocomplete input, we don’t just search via embedding the entire input. We break the input up into logical chunks and perform retrieval ranking against each of them, allowing us to hit all of the necessary fragments. On the indexing side, where we can, we try to parse semantically meaningful chunks of the text, such as a class name or method definitions, but to complement this, we always parse overlapping chunks of text as well. All of this semantic understanding of the chunks really helps us piece together meaningful fragments. Yes, it is great if you can retrieve a 60-line chunk of code that contains the first two lines of the chunk of code you care about. But it is not ideal. If that piece of code is inside of another object, or class, or namespace, it is important that we capture that relationship as well. The more we can capture the understanding a human brings to a codebase, the better.</li><li class="text-base sm:text-lg"><strong>Entity Rarity</strong>: We do something called “Hybrid retrieval,” which runs both embedding-based (i.e. dense) and sparse retrieval systems and combines the results. Research shows that so-called Hybrid approaches can significantly improve accuracy, both because of better recall, and better ranking among recalled items. It appears that dense and sparse retrievers provide complementary document recall, and complementary ranking of recalled items. So by implementing both and using a custom combination of Sparse-Dense similarity to decide what to retrieve, we are able to address entity rarity while still making the most of the power of embeddings to do fuzzy matching.</li><li class="text-base sm:text-lg"><strong>Latency Constraints</strong>: We have implemented a two-stage retrieval system, where across millions of potential entities, we asynchronously build a smaller subset cache of 100s or 1000s of potentially relevant entities based on what the user has done recently. Then synchronously for every autocomplete request we re-rank from this local cache of 100s or 1000s of entities. In this way we can get coverage of the whole codebase, but have a very low-latency impact at the time of an autocomplete request. Oh, and we don’t use a third party embedding API to save on that network latency cost.</li></ul><p class="text-base sm:text-lg">There is a lot we can talk about along each of these avenues, with sub-complications and solutions, but for the sake of this blog post’s length, we will move along.</p><h1 id="bringing-context-aware-everything-to-enterprises"><a href="productionizing-context-aware-everything#bringing-context-aware-everything-to-enterprises" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Bringing Context Aware Everything to Enterprises</h1><p class="text-base sm:text-lg">This context retrieval system, which we have dubbed “Context Aware Everything”, has been a huge technical undertaking, and we have evidence that this will propel Codeium way past its competitors. However, just like any other technical improvement, <strong>if Context Aware Everything is not productionized in a way that satisfies the customer’s requirements, then it is nothing more than a passing technical interest</strong>. From a user’s point of view, context aware everything:</p><ul><li class="text-base sm:text-lg"><strong>Has to work on their codebase</strong>: It is cool if it works on some other person’s repositories, but useful if it works on mine.</li><li class="text-base sm:text-lg"><strong>Has to work locally</strong>: <a class="transition-all duration-150" href="code-security-chatgpt-issues">Code IP is important</a>, so ideally nothing would leave my control (and definitely not my company’s control).</li><li class="text-base sm:text-lg"><strong>Ideally works without buying extra software or requiring manual configuration</strong>: this system is just a way to make existing models perform better. If I have to pay some additional subscription, request a special embedding process, pay for a hosted vector database, pay for an OpenAI key, or manually configure things together, then that’s just unnecessary friction.</li></ul><p class="text-base sm:text-lg">So, at Codeium, how did we address these needs? We compute the embeddings locally and do all of the ranked retrieval locally as well, which means it will work on your repository. This also adds protection over your IP (not shipping your codebase out to a third party embedding service), but if your company doesn’t want to send any code snippets out even for the model inference, our <a target="_blank" rel="noopener noreferrer" href="../enterprise" class="transition-all duration-150">Enterprise</a> plan is fully self-hosted, either on-prem or in your VPC. And don’t want to add some more paid software? Codeium is free, and context aware everything just comes with it automatically. No upselling, no configuration.</p><p class="text-base sm:text-lg"><strong>GitHub Copilot, Amazon Codewhisperer, Tabnine - none of these tools did context retrieval to any level of sophistication similar to Codeium. The only tool out there today that has a resemblance of this context awareness is Sourcegraph’s Cody, but it is not a solution that is productionized properly</strong> - it only operates on open-source repositories, uses third-party LLM APIs as a backend, and requires you to actually purchase Sourcegraph itself, which is an unrelated piece of software to these generative AI models.</p><h1 id="final-thoughts-on-context-awareness"><a href="productionizing-context-aware-everything#final-thoughts-on-context-awareness" aria-hidden="true" tabindex="-1" class="transition-all duration-150"><span class="icon icon-link"></span></a>Final Thoughts on Context Awareness</h1><p class="text-base sm:text-lg">We are proud of the work we’ve done to continue to raise the bar on generative AI model quality in the coding space. By productionizing it properly, context aware everything just works for all developers immediately.</p><p class="text-base sm:text-lg">This announcement is the first in a series of features we’ll be launching whose entire goal is to make Codeium an expert on your codebase, so it can help you solve your problems even better. We will have more technical content related to context awareness coming out soon, such as how the reranking actually works, how we used this logic to also power natural language search capabilities, and what is next in creating “extra brains” that can help you throughout the software development life cycle.</p><p class="text-base sm:text-lg">If this sounds interesting to you and want to work on these kinds of problems, do contact us - we are hiring!</p><div class="mb-8 mt-8 flex w-full items-center justify-center"><a style="text-decoration:none" class="transition-all duration-150" href="../contact"><button style="border:none;background-size:300% 100%;transition:all 0.3s ease;background-image:linear-gradient(-60deg, #09b6a2, #6bf8e7, #09b6a2);background-position:100% 0" class="group flex h-14 items-center justify-center rounded-lg text-lg font-semibold text-white transition-all duration-100 glow-sm hover:glow-md w-48">Contact Us<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="ml-1 h-6 w-6 transition-all duration-150 group-hover:translate-x-2"><path d="M10.061 19.061 17.121 12l-7.06-7.061-2.122 2.122L12.879 12l-4.94 4.939z"></path></svg></button></a></div></div></div><div id="comment"></div></div></div></div><footer class="py-4"><h1 class="gradient-primary gradient-text text-center leading-loose">Suggested Posts</h1><div class="grid grid-cols-1 gap-4 md:grid-cols-2 md:gap-8 lg:grid-cols-3 lg:gap-10"><article class="my-12 flex flex-col items-start justify-start gap-4"><div class="relative grow-0"><a class="cursor-pointer transition-all duration-150" href="codeium-copilot-alternative-in-visual-studio-sublime-eclipse"><img src="../static/images/codeium-hero-blog-image.png" alt="" class="aspect-[4/3] w-full rounded-2xl bg-gray-100 object-cover lg:max-w-[320px]"/></a></div><div class="group relative col-span-1 max-w-xl grow"><div class="flex flex-row items-center gap-2"><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex max-h-[30px] max-w-[160px] items-center justify-center gap-2 overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs text-white sm:!px-2 xl:text-sm"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M6.75 3v2.25M17.25 3v2.25M3 18.75V7.5a2.25 2.25 0 012.25-2.25h13.5A2.25 2.25 0 0121 7.5v11.25m-18 0A2.25 2.25 0 005.25 21h13.5A2.25 2.25 0 0021 18.75m-18 0v-7.5A2.25 2.25 0 015.25 9h13.5A2.25 2.25 0 0121 11.25v7.5m-9-6h.008v.008H12v-.008zM12 15h.008v.008H12V15zm0 2.25h.008v.008H12v-.008zM9.75 15h.008v.008H9.75V15zm0 2.25h.008v.008H9.75v-.008zM7.5 15h.008v.008H7.5V15zm0 2.25h.008v.008H7.5v-.008zm6.75-4.5h.008v.008h-.008v-.008zm0 2.25h.008v.008h-.008V15zm0 2.25h.008v.008h-.008v-.008zm2.25-4.5h.008v.008H16.5v-.008zm0 2.25h.008v.008H16.5V15z"></path></svg>Jul 28, 2023</span><a class="transition-all duration-150" href="tags/product"><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex min-h-[30px] max-w-[160px] items-center overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs capitalize text-white transition-all duration-150 hover:text-surface-300 sm:!px-2 xl:text-sm">product</span></a><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex max-h-[30px] max-w-[160px] items-center gap-2 overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs text-white sm:!px-2 xl:text-sm"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6v6h4.5m4.5 0a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>1<!-- --> min</span></div><a class="cursor-pointer hover:text-gray-200 cursor-pointer transition-all duration-150" href="codeium-copilot-alternative-in-visual-studio-sublime-eclipse"><h5 class="mt-2">Codeium in Visual Studio, Sublime, and Eclipse</h5></a><p class="my-3 leading-6 text-gray-100">Launching Codeium in Visual Studio, Sublime, and Eclipse.</p><a aria-label="Read &quot;Codeium in Visual Studio, Sublime, and Eclipse&quot;" class="cursor-pointer font-medium hover:border-brand-light text-brand-dark hover:text-brand-light transition-all duration-150" href="codeium-copilot-alternative-in-visual-studio-sublime-eclipse">Read more →</a></div></article><article class="my-12 flex flex-col items-start justify-start gap-4"><div class="relative grow-0"><a class="cursor-pointer transition-all duration-150" href="changelist-jul23"><img src="../static/images/codeium-hero-blog-image.png" alt="" class="aspect-[4/3] w-full rounded-2xl bg-gray-100 object-cover lg:max-w-[320px]"/></a></div><div class="group relative col-span-1 max-w-xl grow"><div class="flex flex-row items-center gap-2"><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex max-h-[30px] max-w-[160px] items-center justify-center gap-2 overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs text-white sm:!px-2 xl:text-sm"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M6.75 3v2.25M17.25 3v2.25M3 18.75V7.5a2.25 2.25 0 012.25-2.25h13.5A2.25 2.25 0 0121 7.5v11.25m-18 0A2.25 2.25 0 005.25 21h13.5A2.25 2.25 0 0021 18.75m-18 0v-7.5A2.25 2.25 0 015.25 9h13.5A2.25 2.25 0 0121 11.25v7.5m-9-6h.008v.008H12v-.008zM12 15h.008v.008H12V15zm0 2.25h.008v.008H12v-.008zM9.75 15h.008v.008H9.75V15zm0 2.25h.008v.008H9.75v-.008zM7.5 15h.008v.008H7.5V15zm0 2.25h.008v.008H7.5v-.008zm6.75-4.5h.008v.008h-.008v-.008zm0 2.25h.008v.008h-.008V15zm0 2.25h.008v.008h-.008v-.008zm2.25-4.5h.008v.008H16.5v-.008zm0 2.25h.008v.008H16.5V15z"></path></svg>Aug 7, 2023</span><a class="transition-all duration-150" href="tags/product"><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex min-h-[30px] max-w-[160px] items-center overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs capitalize text-white transition-all duration-150 hover:text-surface-300 sm:!px-2 xl:text-sm">product</span></a><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex max-h-[30px] max-w-[160px] items-center gap-2 overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs text-white sm:!px-2 xl:text-sm"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6v6h4.5m4.5 0a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>2<!-- --> min</span></div><a class="cursor-pointer hover:text-gray-200 cursor-pointer transition-all duration-150" href="changelist-jul23"><h5 class="mt-2">Changelist: July 2023</h5></a><p class="my-3 leading-6 text-gray-100">Codeium updates from July 2023!</p><a aria-label="Read &quot;Changelist: July 2023&quot;" class="cursor-pointer font-medium hover:border-brand-light text-brand-dark hover:text-brand-light transition-all duration-150" href="changelist-jul23">Read more →</a></div></article><article class="my-12 flex flex-col items-start justify-start gap-4"><div class="relative grow-0"><a class="cursor-pointer transition-all duration-150" href="code-llm-eval-why-you-should-not-trust-all-the-numbers-you-see"><img src="https://exafunction.github.io/public/hero/hero_eval_metrics.png" alt="" class="aspect-[4/3] w-full rounded-2xl bg-gray-100 object-cover lg:max-w-[320px]"/></a></div><div class="group relative col-span-1 max-w-xl grow"><div class="flex flex-row items-center gap-2"><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex max-h-[30px] max-w-[160px] items-center justify-center gap-2 overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs text-white sm:!px-2 xl:text-sm"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M6.75 3v2.25M17.25 3v2.25M3 18.75V7.5a2.25 2.25 0 012.25-2.25h13.5A2.25 2.25 0 0121 7.5v11.25m-18 0A2.25 2.25 0 005.25 21h13.5A2.25 2.25 0 0021 18.75m-18 0v-7.5A2.25 2.25 0 015.25 9h13.5A2.25 2.25 0 0121 11.25v7.5m-9-6h.008v.008H12v-.008zM12 15h.008v.008H12V15zm0 2.25h.008v.008H12v-.008zM9.75 15h.008v.008H9.75V15zm0 2.25h.008v.008H9.75v-.008zM7.5 15h.008v.008H7.5V15zm0 2.25h.008v.008H7.5v-.008zm6.75-4.5h.008v.008h-.008v-.008zm0 2.25h.008v.008h-.008V15zm0 2.25h.008v.008h-.008v-.008zm2.25-4.5h.008v.008H16.5v-.008zm0 2.25h.008v.008H16.5V15z"></path></svg>Oct 3, 2023</span><a class="transition-all duration-150" href="tags/product"><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex min-h-[30px] max-w-[160px] items-center overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs capitalize text-white transition-all duration-150 hover:text-surface-300 sm:!px-2 xl:text-sm">product</span></a><span class="rounded-xl px-4 py-1 text-sm bg-gray-100 text-black flex max-h-[30px] max-w-[160px] items-center gap-2 overflow-hidden whitespace-nowrap !bg-surface-800 px-1 text-xs text-white sm:!px-2 xl:text-sm"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6v6h4.5m4.5 0a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>13<!-- --> min</span></div><a class="cursor-pointer hover:text-gray-200 cursor-pointer transition-all duration-150" href="code-llm-eval-why-you-should-not-trust-all-the-numbers-you-see"><h5 class="mt-2">Why You Should Not Trust All the Numbers You See</h5></a><p class="my-3 leading-6 text-gray-100">Our take on industry benchmarks and how to actually evaluate AI code LLMs and tools.</p><a aria-label="Read &quot;Why You Should Not Trust All the Numbers You See&quot;" class="cursor-pointer font-medium hover:border-brand-light text-brand-dark hover:text-brand-light transition-all duration-150" href="code-llm-eval-why-you-should-not-trust-all-the-numbers-you-see">Read more →</a></div></article></div></footer></article></div></main></div><footer aria-labelledby="footer-heading"><h2 id="footer-heading" class="sr-only">Footer</h2><div class="mx-auto max-w-7xl px-6 pb-8 pt-16 sm:pt-24 lg:px-8 lg:pt-32"><div class="xl:grid xl:grid-cols-3 xl:gap-8"><div class="space-y-4"><svg viewBox="0 0 1989 450" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-7"><path fill-rule="evenodd" clip-rule="evenodd" d="M392.971 32.0294L200 225L392.971 417.971C397.314 413.627 400 407.627 400 401V49C400 42.3726 397.314 36.3726 392.971 32.0294Z" fill="#60D5C4"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M392.971 32.0294L200 225L7.02942 32.0294C11.3726 27.6863 17.3726 25 24 25H376C382.627 25 388.627 27.6863 392.971 32.0294Z" fill="#71E9D8"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M7.02944 32.0294L200 225L7.02944 417.971C2.68629 413.627 0 407.627 0 401V49C0 42.3726 2.68629 36.3726 7.02944 32.0294Z" fill="#60D5C4"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M392.971 417.971L200 225L7.02942 417.971C11.3726 422.314 17.3726 425 24 425H376C382.627 425 388.627 422.314 392.971 417.971Z" fill="#71E9D8"></path><rect x="50" y="75" width="300" height="300" rx="2" fill="#09B6A2"></rect><path d="M120.8 315.12C101.24 315.12 91.46 305.34 91.46 285.78V243.84C91.46 236.52 87.86 232.86 80.66 232.86C78.02 232.86 75.8 232.02 74 230.34C72.32 228.66 71.48 226.5 71.48 223.86C71.48 221.1 72.32 218.88 74 217.2C75.8 215.52 78.02 214.68 80.66 214.68C87.86 214.68 91.46 211.02 91.46 203.7V161.76C91.46 142.2 101.24 132.42 120.8 132.42C123.44 132.42 125.6 133.32 127.28 135.12C128.96 136.92 129.8 139.14 129.8 141.78C129.8 144.42 128.96 146.58 127.28 148.26C125.6 149.94 123.44 150.78 120.8 150.78C113.48 150.78 109.82 154.44 109.82 161.76V203.7C109.82 207.9 109.34 211.68 108.38 215.04C107.42 218.4 105.98 221.34 104.06 223.86C107.9 228.78 109.82 235.44 109.82 243.84V285.78C109.82 293.1 113.48 296.76 120.8 296.76C123.44 296.76 125.6 297.6 127.28 299.28C128.96 300.96 129.8 303.18 129.8 305.94C129.8 308.58 128.96 310.74 127.28 312.42C125.6 314.22 123.44 315.12 120.8 315.12ZM156.733 275.88C153.373 275.88 150.433 274.68 147.913 272.28C145.513 269.76 144.313 266.82 144.313 263.46C144.313 259.98 145.513 257.04 147.913 254.64C150.433 252.12 153.373 250.86 156.733 250.86C160.213 250.86 163.153 252.12 165.553 254.64C167.953 257.04 169.153 259.98 169.153 263.46C169.153 266.82 167.953 269.76 165.553 272.28C163.153 274.68 160.213 275.88 156.733 275.88ZM199.623 275.88C196.263 275.88 193.323 274.68 190.803 272.28C188.403 269.76 187.203 266.82 187.203 263.46C187.203 259.98 188.403 257.04 190.803 254.64C193.323 252.12 196.263 250.86 199.623 250.86C203.103 250.86 206.043 252.12 208.443 254.64C210.843 257.04 212.043 259.98 212.043 263.46C212.043 266.82 210.843 269.76 208.443 272.28C206.043 274.68 203.103 275.88 199.623 275.88ZM242.514 275.88C239.154 275.88 236.214 274.68 233.694 272.28C231.294 269.76 230.094 266.82 230.094 263.46C230.094 259.98 231.294 257.04 233.694 254.64C236.214 252.12 239.154 250.86 242.514 250.86C245.994 250.86 248.934 252.12 251.334 254.64C253.734 257.04 254.934 259.98 254.934 263.46C254.934 266.82 253.734 269.76 251.334 272.28C248.934 274.68 245.994 275.88 242.514 275.88ZM278.564 315.12C275.924 315.12 273.764 314.22 272.084 312.42C270.404 310.74 269.564 308.58 269.564 305.94C269.564 303.18 270.404 300.96 272.084 299.28C273.764 297.6 275.924 296.76 278.564 296.76C285.884 296.76 289.544 293.1 289.544 285.78V243.84C289.544 235.44 291.464 228.78 295.304 223.86C293.384 221.34 291.944 218.4 290.984 215.04C290.024 211.68 289.544 207.9 289.544 203.7V161.76C289.544 154.44 285.884 150.78 278.564 150.78C275.924 150.78 273.764 149.94 272.084 148.26C270.404 146.58 269.564 144.42 269.564 141.78C269.564 139.14 270.404 136.92 272.084 135.12C273.764 133.32 275.924 132.42 278.564 132.42C298.124 132.42 307.904 142.2 307.904 161.76V203.7C307.904 211.02 311.504 214.68 318.704 214.68C321.344 214.68 323.504 215.52 325.184 217.2C326.984 218.88 327.884 221.1 327.884 223.86C327.884 226.5 326.984 228.66 325.184 230.34C323.504 232.02 321.344 232.86 318.704 232.86C311.504 232.86 307.904 236.52 307.904 243.84V285.78C307.904 305.34 298.124 315.12 278.564 315.12Z" fill="white"></path><path d="M592.2 363.6C574.68 363.6 558.96 359.28 545.04 350.64C531.36 342 520.44 330.24 512.28 315.36C504.36 300.48 500.4 283.8 500.4 265.32C500.4 246.84 504.36 230.16 512.28 215.28C520.44 200.4 531.36 188.64 545.04 180C558.96 171.36 574.68 167.04 592.2 167.04C609 167.04 624.24 170.52 637.92 177.48C651.84 184.2 662.4 193.44 669.6 205.2L649.08 230.4C645.24 224.88 640.32 219.84 634.32 215.28C628.32 210.72 621.96 207.12 615.24 204.48C608.52 201.84 602.04 200.52 595.8 200.52C584.28 200.52 573.96 203.4 564.84 209.16C555.96 214.68 548.88 222.36 543.6 232.2C538.32 242.04 535.68 253.08 535.68 265.32C535.68 277.56 538.44 288.6 543.96 298.44C549.48 308.04 556.8 315.72 565.92 321.48C575.04 327.24 585.12 330.12 596.16 330.12C602.64 330.12 608.88 329.04 614.88 326.88C621.12 324.72 627.12 321.48 632.88 317.16C638.64 312.84 644.04 307.56 649.08 301.32L669.6 326.52C661.92 337.32 650.88 346.2 636.48 353.16C622.32 360.12 607.56 363.6 592.2 363.6ZM789.536 363.6C771.056 363.6 754.496 359.4 739.856 351C725.456 342.36 714.056 330.72 705.656 316.08C697.256 301.2 693.056 284.28 693.056 265.32C693.056 246.36 697.256 229.56 705.656 214.92C714.056 200.04 725.456 188.4 739.856 180C754.496 171.36 771.056 167.04 789.536 167.04C807.776 167.04 824.096 171.36 838.496 180C853.136 188.4 864.656 200.04 873.056 214.92C881.456 229.56 885.656 246.36 885.656 265.32C885.656 284.28 881.456 301.2 873.056 316.08C864.656 330.72 853.136 342.36 838.496 351C824.096 359.4 807.776 363.6 789.536 363.6ZM789.536 329.76C800.816 329.76 810.896 327 819.776 321.48C828.656 315.72 835.616 308.04 840.656 298.44C845.696 288.6 848.096 277.56 847.856 265.32C848.096 252.84 845.696 241.8 840.656 232.2C835.616 222.36 828.656 214.68 819.776 209.16C810.896 203.64 800.816 200.88 789.536 200.88C778.256 200.88 768.056 203.76 758.936 209.52C750.056 215.04 743.096 222.72 738.056 232.56C733.016 242.16 730.616 253.08 730.856 265.32C730.616 277.56 733.016 288.6 738.056 298.44C743.096 308.04 750.056 315.72 758.936 321.48C768.056 327 778.256 329.76 789.536 329.76ZM1004.9 363.6C987.621 363.6 972.141 359.4 958.461 351C945.021 342.36 934.341 330.72 926.421 316.08C918.501 301.2 914.541 284.28 914.541 265.32C914.541 246.36 918.381 229.56 926.061 214.92C933.981 200.04 944.661 188.4 958.101 180C971.541 171.36 986.781 167.04 1003.82 167.04C1013.18 167.04 1022.18 168.6 1030.82 171.72C1039.7 174.6 1047.62 178.68 1054.58 183.96C1061.54 189 1066.94 194.64 1070.78 200.88C1074.86 206.88 1076.9 213 1076.9 219.24L1066.1 219.96V93.6H1103.18V360H1066.1V315H1073.3C1073.3 320.76 1071.38 326.52 1067.54 332.28C1063.7 337.8 1058.54 342.96 1052.06 347.76C1045.82 352.56 1038.5 356.4 1030.1 359.28C1021.94 362.16 1013.54 363.6 1004.9 363.6ZM1009.94 331.56C1021.22 331.56 1031.18 328.68 1039.82 322.92C1048.46 317.16 1055.18 309.36 1059.98 299.52C1065.02 289.44 1067.54 278.04 1067.54 265.32C1067.54 252.6 1065.02 241.32 1059.98 231.48C1055.18 221.4 1048.46 213.48 1039.82 207.72C1031.18 201.96 1021.22 199.08 1009.94 199.08C998.661 199.08 988.701 201.96 980.061 207.72C971.421 213.48 964.581 221.4 959.541 231.48C954.741 241.32 952.341 252.6 952.341 265.32C952.341 278.04 954.741 289.44 959.541 299.52C964.581 309.36 971.421 317.16 980.061 322.92C988.701 328.68 998.661 331.56 1009.94 331.56ZM1242.42 363.6C1222.98 363.6 1205.7 359.52 1190.58 351.36C1175.7 342.96 1163.94 331.56 1155.3 317.16C1146.9 302.76 1142.7 286.2 1142.7 267.48C1142.7 252.6 1145.1 239.04 1149.9 226.8C1154.7 214.56 1161.3 204 1169.7 195.12C1178.34 186 1188.54 179.04 1200.3 174.24C1212.3 169.2 1225.26 166.68 1239.18 166.68C1251.42 166.68 1262.82 169.08 1273.38 173.88C1283.94 178.44 1293.06 184.8 1300.74 192.96C1308.66 201.12 1314.66 210.84 1318.74 222.12C1323.06 233.16 1325.1 245.28 1324.86 258.48L1324.5 274.32H1170.06L1161.78 244.8H1292.46L1287.06 250.92V242.28C1286.34 234.36 1283.7 227.28 1279.14 221.04C1274.58 214.8 1268.82 209.88 1261.86 206.28C1254.9 202.68 1247.34 200.88 1239.18 200.88C1226.22 200.88 1215.3 203.4 1206.42 208.44C1197.54 213.24 1190.82 220.44 1186.26 230.04C1181.7 239.4 1179.42 251.04 1179.42 264.96C1179.42 278.16 1182.18 289.68 1187.7 299.52C1193.22 309.12 1201.02 316.56 1211.1 321.84C1221.18 327.12 1232.82 329.76 1246.02 329.76C1255.38 329.76 1264.02 328.2 1271.94 325.08C1280.1 321.96 1288.86 316.32 1298.22 308.16L1316.94 334.44C1311.18 340.2 1304.1 345.24 1295.7 349.56C1287.54 353.88 1278.78 357.36 1269.42 360C1260.3 362.4 1251.3 363.6 1242.42 363.6ZM1371.28 360V171H1408.36V360H1371.28ZM1389.28 129.24C1381.36 129.24 1375.24 127.2 1370.92 123.12C1366.6 119.04 1364.44 113.28 1364.44 105.84C1364.44 98.88 1366.6 93.24 1370.92 88.92C1375.48 84.6 1381.6 82.44 1389.28 82.44C1397.2 82.44 1403.32 84.48 1407.64 88.56C1411.96 92.64 1414.12 98.4 1414.12 105.84C1414.12 112.8 1411.84 118.44 1407.28 122.76C1402.96 127.08 1396.96 129.24 1389.28 129.24ZM1531.6 363.6C1518.16 363.6 1506.4 360.48 1496.32 354.24C1486.48 348 1478.8 339.24 1473.28 327.96C1468 316.68 1465.36 303.24 1465.36 287.64V171H1502.44V277.56C1502.44 288.6 1504.12 298.2 1507.48 306.36C1511.08 314.28 1516.12 320.4 1522.6 324.72C1529.32 329.04 1537.36 331.2 1546.72 331.2C1553.68 331.2 1560.04 330.12 1565.8 327.96C1571.56 325.56 1576.48 322.32 1580.56 318.24C1584.88 314.16 1588.24 309.24 1590.64 303.48C1593.04 297.72 1594.24 291.48 1594.24 284.76V171H1631.32V360H1594.24V320.4L1600.72 316.08C1597.84 324.96 1592.92 333 1585.96 340.2C1579.24 347.4 1571.2 353.16 1561.84 357.48C1552.48 361.56 1542.4 363.6 1531.6 363.6ZM1682.61 360V171H1720.05V211.32L1713.21 215.64C1715.13 209.4 1718.13 203.4 1722.21 197.64C1726.53 191.88 1731.69 186.84 1737.69 182.52C1743.93 177.96 1750.53 174.36 1757.49 171.72C1764.69 169.08 1772.01 167.76 1779.45 167.76C1790.25 167.76 1799.73 169.56 1807.89 173.16C1816.05 176.76 1822.77 182.16 1828.05 189.36C1833.33 196.56 1837.17 205.56 1839.57 216.36L1833.81 214.92L1836.33 208.8C1838.97 203.28 1842.57 198.12 1847.13 193.32C1851.93 188.28 1857.33 183.84 1863.33 180C1869.33 176.16 1875.69 173.16 1882.41 171C1889.13 168.84 1895.73 167.76 1902.21 167.76C1916.37 167.76 1928.01 170.64 1937.13 176.4C1946.49 182.16 1953.45 190.92 1958.01 202.68C1962.81 214.44 1965.21 229.08 1965.21 246.6V360H1927.77V248.76C1927.77 237.96 1926.33 229.2 1923.45 222.48C1920.81 215.52 1916.73 210.36 1911.21 207C1905.69 203.64 1898.61 201.96 1889.97 201.96C1883.25 201.96 1876.89 203.16 1870.89 205.56C1865.13 207.72 1860.09 210.84 1855.77 214.92C1851.45 219 1848.09 223.8 1845.69 229.32C1843.29 234.6 1842.09 240.48 1842.09 246.96V360H1804.65V248.04C1804.65 238.2 1803.21 229.92 1800.33 223.2C1797.45 216.24 1793.25 210.96 1787.73 207.36C1782.21 203.76 1775.49 201.96 1767.57 201.96C1760.85 201.96 1754.61 203.16 1748.85 205.56C1743.09 207.72 1738.05 210.84 1733.73 214.92C1729.41 218.76 1726.05 223.44 1723.65 228.96C1721.25 234.24 1720.05 240 1720.05 246.24V360H1682.61Z" fill="#09B6A2"></path></svg><p class="text-sm leading-6 text-gray-200">Your modern coding superpowers.</p><div class="flex"><div class="mr-5"><span class="sr-only">Mail</span><a class="text-sm text-white hover:text-brand-dark" target="_blank" rel="noopener noreferrer" href="mailto:hello@codeium.com"><span class="sr-only">mail</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="h-6 w-6 fill-white text-white hover:fill-brand-dark hover:text-brand-dark"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></a></div><div class="mr-5"><span class="sr-only">Twitter</span><a class="text-sm text-white hover:text-brand-dark" target="_blank" rel="noopener noreferrer" href="https://twitter.com/codeiumdev"><span class="sr-only">twitter</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="h-6 w-6 fill-white text-white hover:fill-brand-dark hover:text-brand-dark"><path d="M23.953 4.57a10 10 0 0 1-2.825.775 4.958 4.958 0 0 0 2.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 0 0-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 0 0-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 0 1-2.228-.616v.06a4.923 4.923 0 0 0 3.946 4.827 4.996 4.996 0 0 1-2.212.085 4.936 4.936 0 0 0 4.604 3.417 9.867 9.867 0 0 1-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 0 0 7.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0 0 24 4.59z"></path></svg></a></div><div class="mr-5"><span class="sr-only">Discord</span><a class="text-sm text-white hover:text-brand-dark" target="_blank" rel="noopener noreferrer" href="https://discord.gg/3XFf78nAx5"><span class="sr-only">discord</span><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 fill-white text-white hover:fill-brand-dark hover:text-brand-dark"><title>Discord</title><path d="M20.317 4.3698a19.7913 19.7913 0 00-4.8851-1.5152.0741.0741 0 00-.0785.0371c-.211.3753-.4447.8648-.6083 1.2495-1.8447-.2762-3.68-.2762-5.4868 0-.1636-.3933-.4058-.8742-.6177-1.2495a.077.077 0 00-.0785-.037 19.7363 19.7363 0 00-4.8852 1.515.0699.0699 0 00-.0321.0277C.5334 9.0458-.319 13.5799.0992 18.0578a.0824.0824 0 00.0312.0561c2.0528 1.5076 4.0413 2.4228 5.9929 3.0294a.0777.0777 0 00.0842-.0276c.4616-.6304.8731-1.2952 1.226-1.9942a.076.076 0 00-.0416-.1057c-.6528-.2476-1.2743-.5495-1.8722-.8923a.077.077 0 01-.0076-.1277c.1258-.0943.2517-.1923.3718-.2914a.0743.0743 0 01.0776-.0105c3.9278 1.7933 8.18 1.7933 12.0614 0a.0739.0739 0 01.0785.0095c.1202.099.246.1981.3728.2924a.077.077 0 01-.0066.1276 12.2986 12.2986 0 01-1.873.8914.0766.0766 0 00-.0407.1067c.3604.698.7719 1.3628 1.225 1.9932a.076.076 0 00.0842.0286c1.961-.6067 3.9495-1.5219 6.0023-3.0294a.077.077 0 00.0313-.0552c.5004-5.177-.8382-9.6739-3.5485-13.6604a.061.061 0 00-.0312-.0286zM8.02 15.3312c-1.1825 0-2.1569-1.0857-2.1569-2.419 0-1.3332.9555-2.4189 2.157-2.4189 1.2108 0 2.1757 1.0952 2.1568 2.419 0 1.3332-.9555 2.4189-2.1569 2.4189zm7.9748 0c-1.1825 0-2.1569-1.0857-2.1569-2.419 0-1.3332.9554-2.4189 2.1569-2.4189 1.2108 0 2.1757 1.0952 2.1568 2.419 0 1.3332-.946 2.4189-2.1568 2.4189Z"></path></svg></a></div><div class="mr-5"><span class="sr-only">LinkedIn</span><a class="text-sm text-white hover:text-brand-dark" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/company/codeiumdev/	"><span class="sr-only">linkedin</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="h-6 w-6 fill-white text-white hover:fill-brand-dark hover:text-brand-dark"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a></div><div class="mr-5"><span class="sr-only">YouTube</span><a class="text-sm text-white hover:text-brand-dark" target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/@codeiumdev"><span class="sr-only">youtube</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="h-6 w-6 fill-white text-white hover:fill-brand-dark hover:text-brand-dark"><path d="M23.499 6.203a3.008 3.008 0 0 0-2.089-2.089c-1.87-.501-9.4-.501-9.4-.501s-7.509-.01-9.399.501a3.008 3.008 0 0 0-2.088 2.09A31.258 31.26 0 0 0 0 12.01a31.258 31.26 0 0 0 .523 5.785 3.008 3.008 0 0 0 2.088 2.089c1.869.502 9.4.502 9.4.502s7.508 0 9.399-.502a3.008 3.008 0 0 0 2.089-2.09 31.258 31.26 0 0 0 .5-5.784 31.258 31.26 0 0 0-.5-5.808zm-13.891 9.4V8.407l6.266 3.604z"></path></svg></a></div></div></div><div class="mt-16 grid grid-cols-2 gap-8 xl:col-span-2 xl:mt-0"><div class="md:grid md:grid-cols-2 md:gap-8"><div><h3 class="text-sm font-semibold leading-6 text-white">Product</h3><ul role="list" class="mt-3 space-y-2"><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../chat">Codeium Chat</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../pricing">Pricing</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../enterprise">Enterprise</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../faq">Supported Languages</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../compare">Compare</a></li></ul></div><div class="mt-10 md:mt-0"><h3 class="text-sm font-semibold leading-6 text-white">Extensions</h3><ul role="list" class="mt-3 space-y-2"><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../vscode_tutorial">Visual Studio Code</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../jetbrains_tutorial">JetBrains</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../vim_tutorial">Neovim / Vim</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../jupyter_tutorial">Jupyter</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../download">See All</a></li></ul></div></div><div class="md:grid md:grid-cols-2 md:gap-8"><div><h3 class="text-sm font-semibold leading-6 text-white">Company</h3><ul role="list" class="mt-3 space-y-2"><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../about">About Us</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../blog">Blog</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../contact">Contact</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://discord.gg/3XFf78nAx5" class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150">Community</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../faq">FAQs</a></li></ul></div><div class="mt-10 md:mt-0"><h3 class="text-sm font-semibold leading-6 text-white">Learn</h3><ul role="list" class="mt-3 space-y-2"><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../glossary">AI Glossary</a></li></ul><h3 class="mt-10 text-sm font-semibold leading-6 text-white">Resources</h3><ul role="list" class="mt-3 space-y-2"><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../terms-of-service-individual">Terms of Service</a></li><li><a class="text-sm leading-6 text-gray-200 hover:text-white transition-all duration-150" href="../privacy-policy">Privacy Policy</a></li></ul></div></div></div></div><div class="mt-16 border-t border-gray-900/10 pt-8 sm:mt-20 lg:mt-24"><p class="text-xs leading-5 text-gray-500">© 2023 Exafunction, Inc. All rights reserved.</p></div></div></footer></div><div id="installModal" class="fixed top-0 hidden h-full w-full bg-gray-900 bg-opacity-80"><div class="flex items-center justify-center px-4 py-48 2xl:container md:px-28 2xl:mx-auto"><div class="relative flex w-96 flex-col items-center justify-center rounded bg-white px-4 py-16 md:w-auto md:px-24 xl:px-36 xl:py-24"><div class="mt-12"><h1 role="main" class="text-center text-3xl font-semibold leading-7 text-primary-800 lg:text-4xl lg:leading-9">Enjoying the Playground?</h1></div><div class="mt"><p class="mt-6 text-center text-base leading-7 text-gray-800 sm:w-80">Install the Codeium Extension to use Codeium for free today!</p></div><a target="_blank" rel="noopener noreferrer" class="mt-6 transition-all duration-150"><button style="border:none;background-size:300% 100%;transition:all 0.3s ease;background-image:linear-gradient(-60deg, #09b6a2, #6bf8e7, #09b6a2);background-position:100% 0" class="group flex h-14 items-center justify-center rounded-lg text-lg font-semibold text-white transition-all duration-100 glow-sm hover:glow-md w-48">Get Codeium<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="ml-1 h-6 w-6 transition-all duration-150 group-hover:translate-x-2"><path d="M10.061 19.061 17.121 12l-7.06-7.061-2.122 2.122L12.879 12l-4.94 4.939z"></path></svg></button></a><a class="mt-6 cursor-pointer border-b border-gray-800 text-center text-base leading-none text-gray-800 hover:border-primary-500 hover:text-primary-500 focus:border-gray-800 focus:outline-none">Not now, let me explore the website more</a></div></div></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"post":{"frontMatter":{"title":"Productionizing Context Aware Everything","date":"2023-08-03T07:00:00.000Z","tags":["industry","enterprise"],"filters":["enterprise_page"],"summary":"Why it is hard to create a context reasoning engine for code LLMs that consistently works.","images":["https://exafunction.github.io/public/hero/hero_productionized_context_awareness.png"],"authors":["nmoy","anshul"],"layout":"PostSimple","featured":false,"dateStr":"August 3, 2023","slug":"productionizing-context-aware-everything","readingTime":{"text":"12 min read","minutes":11.835,"time":710100,"words":2367},"fileName":"productionizing-context-aware-everything.mdx","draft":false,"relatedPosts":[]},"toc":[{"value":"Background on Realtime Context","url":"#background-on-realtime-context","depth":1},{"value":"Challenges with Context Retrieval for Coding Tasks","url":"#challenges-with-context-retrieval-for-coding-tasks","depth":1},{"value":"Cross-Domain","url":"#cross-domain","depth":2},{"value":"Context Fragmentation","url":"#context-fragmentation","depth":2},{"value":"Entity Rarity","url":"#entity-rarity","depth":2},{"value":"Latency Constraints","url":"#latency-constraints","depth":2},{"value":"Productionizing Context Aware Everything","url":"#productionizing-context-aware-everything","depth":1},{"value":"Bringing Context Aware Everything to Enterprises","url":"#bringing-context-aware-everything-to-enterprises","depth":1},{"value":"Final Thoughts on Context Awareness","url":"#final-thoughts-on-context-awareness","depth":1}],"mdxSource":"var Component=(()=\u003e{var m=Object.create;var a=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var c=n=\u003ea(n,\"__esModule\",{value:!0});var w=(n,o)=\u003e()=\u003e(o||n((o={exports:{}}).exports,o),o.exports),b=(n,o)=\u003e{c(n);for(var i in o)a(n,i,{get:o[i],enumerable:!0})},v=(n,o,i)=\u003e{if(o\u0026\u0026typeof o==\"object\"||typeof o==\"function\")for(let t of g(o))!y.call(n,t)\u0026\u0026t!==\"default\"\u0026\u0026a(n,t,{get:()=\u003eo[t],enumerable:!(i=p(o,t))||i.enumerable});return n},k=n=\u003ev(c(a(n!=null?m(f(n)):{},\"default\",n\u0026\u0026n.__esModule\u0026\u0026\"default\"in n?{get:()=\u003en.default,enumerable:!0}:{value:n,enumerable:!0})),n);var u=w((j,d)=\u003e{d.exports=_jsx_runtime});var A={};b(A,{default:()=\u003eI,frontmatter:()=\u003ex});var e=k(u()),x={title:\"Productionizing Context Aware Everything\",date:new Date(1691046e6),tags:[\"industry\",\"enterprise\"],filters:[\"enterprise_page\"],summary:\"Why it is hard to create a context reasoning engine for code LLMs that consistently works.\",images:[\"https://exafunction.github.io/public/hero/hero_productionized_context_awareness.png\"],authors:[\"nmoy\",\"anshul\"],layout:\"PostSimple\",featured:!1};function C(n={}){let{wrapper:o}=n.components||{};return o?(0,e.jsx)(o,Object.assign({},n,{children:(0,e.jsx)(i,{})})):i();function i(){let t=Object.assign({p:\"p\",strong:\"strong\",h1:\"h1\",a:\"a\",span:\"span\",ul:\"ul\",li:\"li\",h2:\"h2\"},n.components),{CenteredImage:s,CustomLink:l,CallToAction:h}=t;return h||r(\"CallToAction\",!0),s||r(\"CenteredImage\",!0),l||r(\"CustomLink\",!0),(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(s,{src:\"https://exafunction.github.io/public/hero/hero_productionized_context_awareness.png\",alt:\"A robot meditating and observing the universe.\"}),(0,e.jsx)(t.p,{children:(0,e.jsx)(t.strong,{children:\"TL;DR We at Codeium are always looking for ways to improve on our enterprise product to give our customers the best suggestions to maximize their productivity. Here, we discuss how we productionized our industry-leading code context collection and prompt building, in a way that actually makes sense for companies. Codeium for Enterprises is the only AI assistant tool that properly productionizes using realtime context.\"})}),(0,e.jsxs)(t.h1,{id:\"background-on-realtime-context\",children:[(0,e.jsx)(t.a,{href:\"#background-on-realtime-context\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Background on Realtime Context\"]}),(0,e.jsxs)(t.p,{children:[\"First, we discussed \",(0,e.jsx)(t.a,{href:\"/blog/what-to-know-about-the-context-going-into-your-llm\",children:\"why context collection is an important, yet tricky, part of an AI code assistance stack\"}),\", and then \",(0,e.jsx)(t.a,{href:\"/blog/context-aware-everything-more-advanced-realtime-context-than-github-copilot\",children:\"we showed that if done properly, advanced context awareness leads to dramatically better performance\"}),\", pushing the quality of Codeium\\u2019s code suggestions far past other industry leaders like GitHub Copilot.\"]}),(0,e.jsxs)(t.p,{children:[\"So now that we have proven how well context retrieval can work, \",(0,e.jsx)(t.strong,{children:\"let us get into the details of what such a retrieval stack looks like\"}),\". Given all of the popular discourse on LLMs, most people would converge on a stack that looks a little like this:\"]}),(0,e.jsxs)(t.ul,{children:[(0,e.jsx)(t.li,{children:\"Indexing (ahead-of-time): First, chunk up your knowledge base into context-sized chunks overlapping chunks somewhat to account for badly placed splits. Then embed these chunks using some 3rd party embedding API (ex. OpenAI ADA embedding), and then store the embeddings in a vector database (ex. PineconeDB).\"}),(0,e.jsx)(t.li,{children:\"Retrieval (real-time): First, use your remote embedding API to embed the user chat message/query. Then, use cosine similarity to match the resulting embedding to the K nearest items in your vector database and put those items into the prompt in addition to the original input. Profit\"})]}),(0,e.jsx)(t.p,{children:(0,e.jsx)(t.strong,{children:\"Naturally, indexing + retrieval is the first thing we tried as well, and it worked! Well, it worked often enough if all we wanted to do was record some cool demo videos of cherry-picked examples. But at Codeium, we have actual users (hundreds of thousands of them), and our features have to work without cherrypicking. So we dug in to understand how to build a system that would address the unique challenges of context for coding.\"})}),(0,e.jsxs)(t.h1,{id:\"challenges-with-context-retrieval-for-coding-tasks\",children:[(0,e.jsx)(t.a,{href:\"#challenges-with-context-retrieval-for-coding-tasks\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Challenges with Context Retrieval for Coding Tasks\"]}),(0,e.jsx)(t.p,{children:\"So let\\u2019s walk through some of these challenges, in no particular order.\"}),(0,e.jsx)(t.p,{children:\"Note that we are focused here on the retrieval system itself and how do we get the accuracy of this system high enough to be useful. None of these address training the autocomplete or chat model to actually use retrieved context as opposed to just shoving in the retrieved chunks and hoping the LLM can figure out what to do with them. But that\\u2019s a topic for another post.\"}),(0,e.jsxs)(t.h2,{id:\"cross-domain\",children:[(0,e.jsx)(t.a,{href:\"#cross-domain\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Cross-Domain\"]}),(0,e.jsxs)(t.p,{children:[\"Take a chat functionality for code assistance. Users often ask questions in natural language, but a lot of the relevant context is in code! It also goes the other way, where if you want to explain some code, the relevant context will be in documentation, which is natural language. The user-specified input is in a different domain from the context that you want to retrieve. \",(0,e.jsx)(t.strong,{children:\"Any production codebase in itself has a mix of natural language and programming languages, and off-the shelf embedding models don\\u2019t capture this cross-modal relationship well.\"})]}),(0,e.jsxs)(t.h2,{id:\"context-fragmentation\",children:[(0,e.jsx)(t.a,{href:\"#context-fragmentation\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Context Fragmentation\"]}),(0,e.jsxs)(t.p,{children:[\"In many applications and most academic benchmarks (eg. WikiQA) the \\u201Ccorrect answer\\u201D is in exactly one place in one document. In code this is almost never the case. \",(0,e.jsx)(t.strong,{children:\"In a common, decently-structured codebase, often 80% of the nominal functionality of a file is imported from libraries that exist all over the codebase. Those libraries will be hard to find based on naive embedding search\"}),\" \\u2013 a general-purpose library will contain very little information on all the ways in which it ends up being used. Somehow your retrieval system has to trace the relationships between files that have little overlapping content, to ensure it pulls all the right items.\"]}),(0,e.jsxs)(t.p,{children:[\"To further complicate the context fragmentation problem, \",(0,e.jsx)(t.strong,{children:\"a question about the same overall topic, asked at two different levels of detail, might require completely different actual fragments of context to answer\"}),\". \\u201CHow does our debugger work\\u201D vs. \\u201CWhat library do we use to parse error stack traces in our debugger\\u201D touch on the same topic, but at very different scopes, requiring different levels of summarization. One might involve pulling the summary of a few classes that interact with each other. The latter might require pulling a specific method from within one of those classes.\"]}),(0,e.jsxs)(t.h2,{id:\"entity-rarity\",children:[(0,e.jsx)(t.a,{href:\"#entity-rarity\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Entity Rarity\"]}),(0,e.jsx)(t.p,{children:\"Prior to embedding search, so-called \\u201Csparse\\u201D retrieval (a fancy word for word-matching algorithms) was state of the art for document retrieval. The reason why embeddings are hugely helpful to context retrieval systems is that they are capable of fuzzy matching, where there\\u2019s a fundamental underlying relationship between the search query and the target entity, even when none of the words used are the same. This way, a user can ask very vague questions without any reference to a specific filename, and still get reasonable responses.\"}),(0,e.jsxs)(t.p,{children:[\"However, \",(0,e.jsx)(t.a,{href:\"https://www.semanticscholar.org/reader/f7a6b57adebb5f6a10d16e120f0b0ef55aab7b2b\",children:\"research shows\"}),\" that \",(0,e.jsx)(t.strong,{children:\"for rare entities, and especially zero-shot entities that the embedding model did not see at training, embedding-based retrieval systems still significantly underperform traditional \\u201CSparse\\u201D (word matching) based retrievers\"}),\". The research goes into more detail on why, but as some intuition, imagine studying for a test: if you need to know a formula well enough to actually use it to solve a problem, you need to have seen the pattern more times than if you just want to know the the \\u201Cgist\\u201D of an idea. In a similar way, rarer items will be less well represented by an embedding model.\"]}),(0,e.jsxs)(t.p,{children:[(0,e.jsx)(t.strong,{children:\"Unfortunately, rare entities are very important for any coding related task.\"}),\" Code is full of them - unlike natural language, code is special in that you can use arbitrary strings of characters for an entity, or more interestingly, redefine what an entity means within the context of your repository, even if that differs from what it means in a different repository. In a very fundamental sense, this is the entire point of code. And once you define that new entity, its name may appear only a handful of times in a codebase: once when the function is defined and just a few more times when that function is called.\"]}),(0,e.jsx)(t.p,{children:\"But to simultaneously raise the stakes, it is also very important for our system to get the specific entity correctly to provide a useful suggestion. For example, we need to know exactly what the parameter list of a function is, not that of a similar function that does something similar.\"}),(0,e.jsxs)(t.h2,{id:\"latency-constraints\",children:[(0,e.jsx)(t.a,{href:\"#latency-constraints\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Latency Constraints\"]}),(0,e.jsxs)(t.p,{children:[\"For autocomplete, completion requests are produced with every keystroke. The typical autocompletion takes 100ms, and you cannot really get a whole lot slower if you want to keep developers in the flow. So, \",(0,e.jsx)(t.strong,{children:\"if a context retrieval system is going to be used, it can\\u2019t add on much more than 20ms on average or it will start to negatively affect the user experience\"}),\".\"]}),(0,e.jsx)(t.p,{children:\"Performing an embedding of the input takes about 100ms, and if you were to use a remote service or embedding API, you would incur another 100ms or so in network latency to the remote service. The actual similarity calculation is pretty fast since it boils down to just a matrix multiplication, but the embedding makes it impossible to do for every autocomplete request.\"}),(0,e.jsx)(t.p,{children:\"Sparse heuristics on the other hand have less up-front compute cost, but this cost scales with the number of items that we need to retrieve and rank, and quickly becomes unmanageable over millions of records.\"}),(0,e.jsxs)(t.h1,{id:\"productionizing-context-aware-everything\",children:[(0,e.jsx)(t.a,{href:\"#productionizing-context-aware-everything\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Productionizing Context Aware Everything\"]}),(0,e.jsxs)(t.p,{children:[\"Of course we won\\u2019t just list out challenges without providing a little bit of insight in how we solved these issues to get the results demonstrated in the \",(0,e.jsx)(t.a,{href:\"/blog/context-aware-everything-more-advanced-realtime-context-than-github-copilot\",children:\"previous post\"}),\".\"]}),(0,e.jsxs)(t.ul,{children:[(0,e.jsxs)(t.li,{children:[(0,e.jsx)(t.strong,{children:\"Cross Domain\"}),\": We trained our own embedding model specifically to map between natural language and code using docstrings as the natural language. This is actually what underlies our \",(0,e.jsx)(t.a,{href:\"https://www.youtube.com/watch?v=fk5pod16678\",children:\"search capability\"}),\", which, as an aside, we are slowly going to be folding directly into chat as chat becomes more \\u201Ccontext aware\\u201D to be able to answer these direct search questions. With this, it is important for us to semantically parse concepts like docstrings from the code itself, and this led to our \",(0,e.jsx)(t.a,{href:\"https://github.com/Exafunction/codeium-parse\",children:\"codeium-parse library\"}),\". When we do embedding retrieval, we might get a hit on the docstring specifically to match the natural language, and that lets us retrieve the code snippet, which is what the user actually needs. When indexing a codebase, we often index multiple parts of the same code item, allowing us more opportunities to get a hit since we have semantically linked these parts via parsing.\"]}),(0,e.jsxs)(t.li,{children:[(0,e.jsx)(t.strong,{children:\"Context Fragmentation\"}),\": The first step is multi-key retrieval. Whether the input is a chat question or autocomplete input, we don\\u2019t just search via embedding the entire input. We break the input up into logical chunks and perform retrieval ranking against each of them, allowing us to hit all of the necessary fragments. On the indexing side, where we can, we try to parse semantically meaningful chunks of the text, such as a class name or method definitions, but to complement this, we always parse overlapping chunks of text as well. All of this semantic understanding of the chunks really helps us piece together meaningful fragments. Yes, it is great if you can retrieve a 60-line chunk of code that contains the first two lines of the chunk of code you care about. But it is not ideal. If that piece of code is inside of another object, or class, or namespace, it is important that we capture that relationship as well. The more we can capture the understanding a human brings to a codebase, the better.\"]}),(0,e.jsxs)(t.li,{children:[(0,e.jsx)(t.strong,{children:\"Entity Rarity\"}),\": We do something called \\u201CHybrid retrieval,\\u201D which runs both embedding-based (i.e. dense) and sparse retrieval systems and combines the results. Research shows that so-called Hybrid approaches can significantly improve accuracy, both because of better recall, and better ranking among recalled items. It appears that dense and sparse retrievers provide complementary document recall, and complementary ranking of recalled items. So by implementing both and using a custom combination of Sparse-Dense similarity to decide what to retrieve, we are able to address entity rarity while still making the most of the power of embeddings to do fuzzy matching.\"]}),(0,e.jsxs)(t.li,{children:[(0,e.jsx)(t.strong,{children:\"Latency Constraints\"}),\": We have implemented a two-stage retrieval system, where across millions of potential entities, we asynchronously build a smaller subset cache of 100s or 1000s of potentially relevant entities based on what the user has done recently. Then synchronously for every autocomplete request we re-rank from this local cache of 100s or 1000s of entities. In this way we can get coverage of the whole codebase, but have a very low-latency impact at the time of an autocomplete request. Oh, and we don\\u2019t use a third party embedding API to save on that network latency cost.\"]})]}),(0,e.jsx)(t.p,{children:\"There is a lot we can talk about along each of these avenues, with sub-complications and solutions, but for the sake of this blog post\\u2019s length, we will move along.\"}),(0,e.jsxs)(t.h1,{id:\"bringing-context-aware-everything-to-enterprises\",children:[(0,e.jsx)(t.a,{href:\"#bringing-context-aware-everything-to-enterprises\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Bringing Context Aware Everything to Enterprises\"]}),(0,e.jsxs)(t.p,{children:[\"This context retrieval system, which we have dubbed \\u201CContext Aware Everything\\u201D, has been a huge technical undertaking, and we have evidence that this will propel Codeium way past its competitors. However, just like any other technical improvement, \",(0,e.jsx)(t.strong,{children:\"if Context Aware Everything is not productionized in a way that satisfies the customer\\u2019s requirements, then it is nothing more than a passing technical interest\"}),\". From a user\\u2019s point of view, context aware everything:\"]}),(0,e.jsxs)(t.ul,{children:[(0,e.jsxs)(t.li,{children:[(0,e.jsx)(t.strong,{children:\"Has to work on their codebase\"}),\": It is cool if it works on some other person\\u2019s repositories, but useful if it works on mine.\"]}),(0,e.jsxs)(t.li,{children:[(0,e.jsx)(t.strong,{children:\"Has to work locally\"}),\": \",(0,e.jsx)(t.a,{href:\"/blog/code-security-chatgpt-issues\",children:\"Code IP is important\"}),\", so ideally nothing would leave my control (and definitely not my company\\u2019s control).\"]}),(0,e.jsxs)(t.li,{children:[(0,e.jsx)(t.strong,{children:\"Ideally works without buying extra software or requiring manual configuration\"}),\": this system is just a way to make existing models perform better. If I have to pay some additional subscription, request a special embedding process, pay for a hosted vector database, pay for an OpenAI key, or manually configure things together, then that\\u2019s just unnecessary friction.\"]})]}),(0,e.jsxs)(t.p,{children:[\"So, at Codeium, how did we address these needs? We compute the embeddings locally and do all of the ranked retrieval locally as well, which means it will work on your repository. This also adds protection over your IP (not shipping your codebase out to a third party embedding service), but if your company doesn\\u2019t want to send any code snippets out even for the model inference, our \",(0,e.jsx)(t.a,{href:\"https://codeium.com/enterprise\",children:\"Enterprise\"}),\" plan is fully self-hosted, either on-prem or in your VPC. And don\\u2019t want to add some more paid software? Codeium is free, and context aware everything just comes with it automatically. No upselling, no configuration.\"]}),(0,e.jsxs)(t.p,{children:[(0,e.jsx)(t.strong,{children:\"GitHub Copilot, Amazon Codewhisperer, Tabnine - none of these tools did context retrieval to any level of sophistication similar to Codeium. The only tool out there today that has a resemblance of this context awareness is Sourcegraph\\u2019s Cody, but it is not a solution that is productionized properly\"}),\" - it only operates on open-source repositories, uses third-party LLM APIs as a backend, and requires you to actually purchase Sourcegraph itself, which is an unrelated piece of software to these generative AI models.\"]}),(0,e.jsxs)(t.h1,{id:\"final-thoughts-on-context-awareness\",children:[(0,e.jsx)(t.a,{href:\"#final-thoughts-on-context-awareness\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(t.span,{className:\"icon icon-link\"})}),\"Final Thoughts on Context Awareness\"]}),(0,e.jsx)(t.p,{children:\"We are proud of the work we\\u2019ve done to continue to raise the bar on generative AI model quality in the coding space. By productionizing it properly, context aware everything just works for all developers immediately.\"}),(0,e.jsx)(t.p,{children:\"This announcement is the first in a series of features we\\u2019ll be launching whose entire goal is to make Codeium an expert on your codebase, so it can help you solve your problems even better. We will have more technical content related to context awareness coming out soon, such as how the reranking actually works, how we used this logic to also power natural language search capabilities, and what is next in creating \\u201Cextra brains\\u201D that can help you throughout the software development life cycle.\"}),(0,e.jsx)(t.p,{children:\"If this sounds interesting to you and want to work on these kinds of problems, do contact us - we are hiring!\"}),(0,e.jsx)(\"div\",{className:\"mb-8 mt-8 flex w-full items-center justify-center\",children:(0,e.jsx)(l,{href:\"/contact\",analytics:{component_type:\"button\",component_name:\"contact_codeium\"},style:{textDecoration:\"none\"},children:(0,e.jsx)(h,{label:\"Contact Us\"})})})]})}}var I=C;function r(n,o){throw new Error(\"Expected \"+(o?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return A;})();\n;return Component;"},"authorDetails":[{"name":"Nick Moy","occupation":"Software Engineer","company":"Exafunction","linkedin":"https://www.linkedin.com/in/nicholas-moy/"},{"name":"Anshul Ramachandran","occupation":"Software Engineer","company":"Exafunction","linkedin":"https://www.linkedin.com/in/anshul-ramachandran/"}],"prev":{"title":"Codeium in Visual Studio, Sublime, and Eclipse","date":"2023-07-28T07:00:00.000Z","tags":["product"],"summary":"Launching Codeium in Visual Studio, Sublime, and Eclipse.","images":["/static/images/codeium-hero-blog-image.png"],"authors":["default"],"relatedPosts":["how-is-codeium-free"],"layout":"PostSimple","dateStr":"July 28, 2023","slug":"codeium-copilot-alternative-in-visual-studio-sublime-eclipse","readingTime":{"text":"2 min read","minutes":1.25,"time":75000,"words":250},"fileName":"codeium-copilot-alternative-in-visual-studio-sublime-eclipse.mdx","draft":false,"featured":false},"next":{"title":"Changelist: July 2023","date":"2023-08-07T07:00:00.000Z","tags":["product","changelist"],"summary":"Codeium updates from July 2023!","images":["/static/images/codeium-hero-blog-image.png"],"authors":["default"],"relatedPosts":["changelist-jun23","changelist-may23","changelist-apr23"],"layout":"PostSimple","dateStr":"August 7, 2023","slug":"changelist-jul23","readingTime":{"text":"2 min read","minutes":1.89,"time":113400,"words":378},"fileName":"changelist-jul23.mdx","draft":false,"featured":false},"featuredPosts":[{"title":"Why You Should Not Trust All the Numbers You See","date":"2023-10-03T07:00:00.000Z","tags":["product","enterprise"],"filters":["enterprise_page"],"summary":"Our take on industry benchmarks and how to actually evaluate AI code LLMs and tools.","images":["https://exafunction.github.io/public/hero/hero_eval_metrics.png"],"authors":["matt","mehul","douglas"],"layout":"PostSimple","featured":true,"dateStr":"October 3, 2023","slug":"code-llm-eval-why-you-should-not-trust-all-the-numbers-you-see","readingTime":{"text":"13 min read","minutes":12.655,"time":759300,"words":2531},"fileName":"code-llm-eval-why-you-should-not-trust-all-the-numbers-you-see.mdx","draft":false,"relatedPosts":[]},{"title":"Context Aware Everything: More Advanced Realtime Context than GitHub Copilot","date":"2023-07-24T07:00:00.000Z","tags":["industry","enterprise"],"filters":["enterprise_page"],"summary":"A deep dive into context awareness of Codeium and how it stacks up against GitHub Copilot and CopilotX.","images":["https://exafunction.github.io/public/hero/hero_context_module.png"],"authors":["nmoy"],"layout":"PostSimple","featured":true,"dateStr":"July 24, 2023","slug":"context-aware-everything-more-advanced-realtime-context-than-github-copilot","readingTime":{"text":"11 min read","minutes":10.325,"time":619500,"words":2065},"fileName":"context-aware-everything-more-advanced-realtime-context-than-github-copilot.mdx","draft":false,"relatedPosts":[]},{"title":"Code Suggestions You Don’t Get from Copilot: In-line FIM","date":"2023-06-09T07:00:00.000Z","tags":["technical","enterprise"],"summary":"In-line Fill-in-the-Middle suggestions, valuable suggestions produced only by Codeium.","images":["https://exafunction.github.io/public/hero/hero_inline_fim.png"],"authors":["nick"],"layout":"PostSimple","featured":true,"relatedPosts":["how-to-make-ai-ux-your-moat"],"dateStr":"June 9, 2023","slug":"inline-fim-code-suggestions","readingTime":{"text":"5 min read","minutes":4.595,"time":275700,"words":919},"fileName":"inline-fim-code-suggestions.mdx","draft":false},{"title":"GitHub Copilot Emits GPL. Codeium Does Not.","date":"2023-04-20T07:00:00.000Z","tags":["company","enterprise"],"filters":["enterprise_page"],"summary":"Demonstrating that GitHub Copilot trains on non-permissive licenses and is unable to filter out suggestions properly, while Codeium does not expose users to legal risk.","images":["/static/images/hero_copilot_gpl.png"],"authors":["default"],"layout":"PostSimple","featured":true,"dateStr":"April 20, 2023","slug":"copilot-trains-on-gpl-codeium-does-not","readingTime":{"text":"10 min read","minutes":9.55,"time":573000,"words":1910},"fileName":"copilot-trains-on-gpl-codeium-does-not.mdx","draft":false,"relatedPosts":[]}],"relatedPosts":[]},"__N_SSG":true},"page":"/blog/[...slug]","query":{"slug":["productionizing-context-aware-everything"]},"buildId":"VBXOvo5BSUCiJzjePzBK3","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>